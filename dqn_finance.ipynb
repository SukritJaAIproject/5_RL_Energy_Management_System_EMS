{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    %tensorflow_version 2.x\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "  !sudo apt-get install -y xvfb ffmpeg x11-utils\n",
    "  !pip install -q 'gym==0.10.11'\n",
    "  !pip install -q 'imageio==2.4.0'\n",
    "  !pip install -q PILLOW\n",
    "  !pip install -q 'pyglet==1.3.2'\n",
    "  !pip install -q pyvirtualdisplay\n",
    "  !pip install -q tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.ddpg import actor_network\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.ddpg import ddpg_agent\n",
    "\n",
    "from tf_agents.agents.dqn import dqn_agent\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.eval import metric_utils\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.networks import q_network\n",
    "from tf_agents.policies import random_tf_policy\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.trajectories import trajectory\n",
    "from tf_agents.trajectories import policy_step\n",
    "from tf_agents.utils import common\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.utils import seeding\n",
    "from gym.envs.registration import register\n",
    "import PIL.ImageDraw\n",
    "import PIL.Image\n",
    "from PIL import ImageFont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SimpleGameOfLifeEnv(gym.Env):\n",
    "#     metadata = {\n",
    "#         'render.modes': ['human', 'rgb_array'],\n",
    "#         'video.frames_per_second': 1\n",
    "#     }\n",
    "\n",
    "#     STATE_ELEMENTS = 7\n",
    "#     STATES = ['age', 'salary', 'home_value', 'home_loan', 'req_home_pmt', \n",
    "#               'acct_tax_adv', 'acct_tax', \"expenses\", \"actual_home_pmt\", \"tax_deposit\", \n",
    "#               \"tax_adv_deposit\", \"net_worth\"]\n",
    "#     STATE_AGE = 0\n",
    "#     STATE_SALARY = 1\n",
    "#     STATE_HOME_VALUE = 2\n",
    "#     STATE_HOME_LOAN = 3\n",
    "#     STATE_HOME_REQ_PAYMENT = 4\n",
    "#     STATE_SAVE_TAX_ADV = 5\n",
    "#     STATE_SAVE_TAXABLE = 6\n",
    "\n",
    "#     MEG = 1.0e6\n",
    "\n",
    "#     ACTION_ELEMENTS = 4\n",
    "#     ACTION_HOME_LOAN = 0\n",
    "#     ACTION_SAVE_TAX_ADV = 1\n",
    "#     ACTION_SAVE_TAXABLE = 2\n",
    "#     ACTION_LUXURY = 3\n",
    "\n",
    "#     INFLATION = (0.015)/12.0\n",
    "#     INTEREST = (0.05)/12.0\n",
    "#     TAX_RATE = (.142)/12.0\n",
    "#     EXPENSES = 0.6\n",
    "#     INVEST_RETURN = 0.065/12.0\n",
    "#     SALARY_LOW = 40000.0\n",
    "#     SALARY_HIGH = 60000.0\n",
    "#     START_AGE = 18\n",
    "#     RETIRE_AGE = 80\n",
    "\n",
    "#     def __init__(self, goal_velocity=0):\n",
    "#         self.verbose = False\n",
    "#         self.viewer = None\n",
    "\n",
    "#         self.action_space = spaces.Box(\n",
    "#           low=0.0,\n",
    "#           high=1.0,\n",
    "#           shape=(SimpleGameOfLifeEnv.ACTION_ELEMENTS,),\n",
    "#           dtype=np.float32\n",
    "#         )\n",
    "#         self.observation_space = spaces.Box(\n",
    "#           low=0,\n",
    "#           high=2,\n",
    "#           shape=(SimpleGameOfLifeEnv.STATE_ELEMENTS,),\n",
    "#           dtype=np.float32\n",
    "#         )\n",
    "\n",
    "#         self.seed()\n",
    "#         self.reset()\n",
    "\n",
    "#         self.state_log = []\n",
    "\n",
    "#     def seed(self, seed=None):\n",
    "#         self.np_random, seed = seeding.np_random(seed)\n",
    "#         return [seed]\n",
    "\n",
    "#     def _calc_net_worth(self):\n",
    "#         home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "#         principal = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n",
    "#         worth = home_value - principal\n",
    "#         worth += self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV]\n",
    "#         worth += self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE]\n",
    "#         return worth\n",
    "\n",
    "#     def _eval_action(self, action, payment):\n",
    "#         # Calculate actions\n",
    "#         act_home_payment = action[SimpleGameOfLifeEnv.ACTION_HOME_LOAN]\n",
    "#         act_tax_adv_pay = action[SimpleGameOfLifeEnv.ACTION_SAVE_TAX_ADV]\n",
    "#         act_taxable = action[SimpleGameOfLifeEnv.ACTION_SAVE_TAXABLE]\n",
    "#         act_luxury = action[SimpleGameOfLifeEnv.ACTION_LUXURY]\n",
    "#         if payment <=0:\n",
    "#             act_home_payment = 0\n",
    "#         total_act = act_home_payment + act_tax_adv_pay + act_taxable + act_luxury + self.expenses\n",
    "\n",
    "#         if total_act <1e-2:\n",
    "#             pct_home_payment = 0\n",
    "#             pct_tax_adv_pay = 0\n",
    "#             pct_taxable = 0\n",
    "#             pct_luxury = 0\n",
    "#         else:\n",
    "#             pct_home_payment = act_home_payment / total_act\n",
    "#             pct_tax_adv_pay = act_tax_adv_pay / total_act\n",
    "#             pct_taxable = act_taxable / total_act\n",
    "#             pct_luxury = act_luxury / total_act\n",
    "\n",
    "#         return pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury\n",
    "\n",
    "#     def step(self, action):\n",
    "#         self.last_action = action\n",
    "#         age = self.state[SimpleGameOfLifeEnv.STATE_AGE]\n",
    "#         salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]\n",
    "#         home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "#         principal = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n",
    "#         payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n",
    "#         net1 = self._calc_net_worth()\n",
    "#         remaining_salary = salary\n",
    "\n",
    "#         # Calculate actions\n",
    "#         pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury = \\\n",
    "#             self._eval_action(action,payment)\n",
    "\n",
    "#         # Expenses\n",
    "#         current_expenses = salary * self.expenses\n",
    "#         remaining_salary -= current_expenses\n",
    "#         if self.verbose:\n",
    "#             print(f\"Expenses: {current_expenses}\")\n",
    "#             print(f\"Remaining Salary: {remaining_salary}\")\n",
    "\n",
    "#         # Tax advantaged deposit action\n",
    "#         my_tax_adv_deposit = min(salary * pct_tax_adv_pay, remaining_salary)\n",
    "#         my_tax_adv_deposit = min(my_tax_adv_deposit, \\\n",
    "#             self.year_tax_adv_deposit_left) # Govt CAP\n",
    "#         self.year_tax_adv_deposit_left -= my_tax_adv_deposit\n",
    "#         remaining_salary -= my_tax_adv_deposit\n",
    "#         tax_adv_deposit = my_tax_adv_deposit * 1.05 # Company match\n",
    "#         self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] += \\\n",
    "#             int(tax_adv_deposit)\n",
    "\n",
    "#         if self.verbose:\n",
    "#             print(f\"IRA Deposit: {tax_adv_deposit}\")\n",
    "#             print(f\"Remaining Salary: {remaining_salary}\")\n",
    "\n",
    "#         # Tax\n",
    "#         remaining_salary -= remaining_salary * SimpleGameOfLifeEnv.TAX_RATE\n",
    "#         if self.verbose:\n",
    "#             print(f\"Tax Salary: {remaining_salary}\")\n",
    "\n",
    "#         # Home payment\n",
    "#         actual_payment = min(salary * pct_home_payment, remaining_salary)\n",
    "\n",
    "#         if principal>0:\n",
    "#             ipart = principal * SimpleGameOfLifeEnv.INTEREST\n",
    "#             ppart = actual_payment - ipart\n",
    "#             principal = int(principal-ppart)\n",
    "#             if principal<=0:\n",
    "#                 principal = 0\n",
    "#                 self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = 0\n",
    "#             elif actual_payment < payment:\n",
    "#                 self.late_count += 1\n",
    "#                 if self.late_count>15:\n",
    "#                     sell = (home_value-principal)/2\n",
    "#                     sell -= 20000\n",
    "#                     sell = max(sell,0)\n",
    "#                     self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += sell\n",
    "#                     principal = 0\n",
    "#                     home_value = 0\n",
    "#                     self.expenses += .3\n",
    "#                     self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = 0\n",
    "#                     if self.verbose:\n",
    "#                         print(f\"Foreclosure!!\")\n",
    "#                     else:\n",
    "#                         late_fee = payment * 0.1\n",
    "#                         principal += late_fee\n",
    "#                     if self.verbose:\n",
    "#                         print(f\"Late Fee: {late_fee}\")\n",
    "\n",
    "\n",
    "#         self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN] = principal\n",
    "#         remaining_salary -= actual_payment\n",
    "\n",
    "#         if self.verbose:\n",
    "#             print(f\"Home Payment: {actual_payment}\")\n",
    "#             print(f\"Remaining Salary: {remaining_salary}\")\n",
    "\n",
    "#         # Taxable savings\n",
    "#         actual_savings = remaining_salary * pct_taxable\n",
    "#         self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += actual_savings\n",
    "#         remaining_salary -= actual_savings\n",
    "\n",
    "#         if self.verbose:\n",
    "#             print(f\"Tax Save: {actual_savings}\")\n",
    "#             print(f\"Remaining Salary (goes to Luxury): {remaining_salary}\")\n",
    "\n",
    "#         # Investment income\n",
    "#         return_taxable = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] * \\\n",
    "#             self.invest_return\n",
    "#         return_tax_adv = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] * \\\n",
    "#             self.invest_return\n",
    "\n",
    "#         return_taxable *= 1-SimpleGameOfLifeEnv.TAX_RATE\n",
    "#         self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += return_taxable\n",
    "#         self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] += return_tax_adv\n",
    "\n",
    "#         # Yearly events\n",
    "#         if age>0 and age % 12 == 0:\n",
    "#             self.perform_yearly()\n",
    "\n",
    "#         # Monthly events\n",
    "#         self.state[SimpleGameOfLifeEnv.STATE_AGE] += 1\n",
    "      \n",
    "#         # Time to retire (by age?)\n",
    "#         done = self.state[SimpleGameOfLifeEnv.STATE_AGE] > \\\n",
    "#             (SimpleGameOfLifeEnv.RETIRE_AGE*12)\n",
    "\n",
    "#         # Calculate reward \n",
    "#         net2 = self._calc_net_worth()\n",
    "#         reward = net2 - net1\n",
    "\n",
    "#         # Track progress\n",
    "#         if self.verbose:\n",
    "#             print(f\"Networth: {nw}\")\n",
    "#             print(f\"*** End Step {self.step_num}: State={self.state}, \\\n",
    "#                 Reward={reward}\")\n",
    "#         self.state_log.append(self.state + [current_expenses, actual_payment, \n",
    "#         actual_savings, my_tax_adv_deposit, net2])\n",
    "#         self.step_num += 1\n",
    "\n",
    "#         # Normalize state and finish up\n",
    "#         norm_state = [x/SimpleGameOfLifeEnv.MEG for x in self.state]\n",
    "#         return norm_state, reward/SimpleGameOfLifeEnv.MEG, done, {}\n",
    "\n",
    "#         def perform_yearly(self):\n",
    "#             salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]\n",
    "#             home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "\n",
    "#             self.inflation = SimpleGameOfLifeEnv.INTEREST + \\\n",
    "#               self.np_random.normal(loc=0,scale=1e-2)\n",
    "#             self.invest_return = SimpleGameOfLifeEnv.INVEST_RETURN + \\\n",
    "#               self.np_random.normal(loc=0,scale=1e-2)\n",
    "\n",
    "#             self.year_tax_adv_deposit_left = 19000\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_SALARY] = \\\n",
    "#             int(salary * (1+self.inflation))\n",
    "\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE] \\\n",
    "#             = int(home_value * (1+self.inflation))\n",
    "\n",
    "#         def reset(self):\n",
    "#             self.expenses = SimpleGameOfLifeEnv.EXPENSES\n",
    "#             self.late_count = 0\n",
    "#             self.step_num = 0\n",
    "#             self.last_action = [0] * SimpleGameOfLifeEnv.ACTION_ELEMENTS\n",
    "#             self.state = [0] * SimpleGameOfLifeEnv.STATE_ELEMENTS\n",
    "#             self.state_log = []\n",
    "#             salary = float(self.np_random.randint(low=SimpleGameOfLifeEnv.SALARY_LOW,\n",
    "#                                    high=SimpleGameOfLifeEnv.SALARY_HIGH))\n",
    "#             house_mult = self.np_random.uniform(low=1.5,high=4)\n",
    "#             value = round(salary*house_mult)\n",
    "#             p = (value*0.9)\n",
    "#             i = SimpleGameOfLifeEnv.INTEREST\n",
    "#             n = 30 * 12\n",
    "#             m = float(int(p *  ( i * (1 + i)**n ) / ( (1 + i)**n - 1)))\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_AGE] = \\\n",
    "#             SimpleGameOfLifeEnv.START_AGE * 12\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_SALARY] = salary / 12.0\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE] = value\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN] = p\n",
    "#             self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = m\n",
    "#             self.year_tax_adv_deposit_left = 19000\n",
    "#             self.perform_yearly()\n",
    "#             return np.array(self.state)\n",
    "\n",
    "#         def render(self, mode='human'):\n",
    "#             screen_width = 600\n",
    "#             screen_height = 400\n",
    "\n",
    "#             img = PIL.Image.new('RGB', (600, 400))\n",
    "#             d = PIL.ImageDraw.Draw(img)\n",
    "#             font = ImageFont.load_default()\n",
    "#             y = 0\n",
    "#             _, height = d.textsize(\"W\", font)\n",
    "\n",
    "#             age = self.state[SimpleGameOfLifeEnv.STATE_AGE]\n",
    "#             salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]*12\n",
    "#             home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "#             home_loan = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n",
    "#             home_payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n",
    "#             balance_tax_adv = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV]\n",
    "#             balance_taxable = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE]\n",
    "#             net_worth = self._calc_net_worth()\n",
    "\n",
    "#             d.text((0, y), f\"Age: {age/12}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Salary: {salary:,}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Home Value: {home_value:,}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Home Loan: {home_loan:,}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Home Payment: {home_payment:,}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Balance Tax Adv: {balance_tax_adv:,}\", \\\n",
    "#                    fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Balance Taxable: {balance_taxable:,}\", \\\n",
    "#                    fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Net Worth: {net_worth:,}\", fill=(0, 255, 0))\n",
    "#             y+=height*2\n",
    "\n",
    "#             payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n",
    "#             pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury = \\\n",
    "#               self._eval_action(self.last_action,payment)\n",
    "#             d.text((0, y), f\"Percent Home Payment: {pct_home_payment}\", \\\n",
    "#                    fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Percent Tax Adv: {pct_tax_adv_pay}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Percent Taxable: {pct_taxable}\", fill=(0, 255, 0))\n",
    "#             y+=height\n",
    "#             d.text((0, y), f\"Percent Luxury: {pct_luxury}\", fill=(0, 255, 0))\n",
    "\n",
    "#             return np.array(img)\n",
    "\n",
    "#             def close(self):\n",
    "#                 pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGameOfLifeEnv(gym.Env):\n",
    "    metadata = {\n",
    "        'render.modes': ['human', 'rgb_array'],\n",
    "        'video.frames_per_second': 1\n",
    "    }\n",
    "\n",
    "    STATE_ELEMENTS = 7\n",
    "    STATES = ['age', 'salary', 'home_value', 'home_loan', 'req_home_pmt', \n",
    "              'acct_tax_adv', 'acct_tax', \"expenses\", \"actual_home_pmt\", \"tax_deposit\", \n",
    "              \"tax_adv_deposit\", \"net_worth\"]\n",
    "    STATE_AGE = 0\n",
    "    STATE_SALARY = 1\n",
    "    STATE_HOME_VALUE = 2\n",
    "    STATE_HOME_LOAN = 3\n",
    "    STATE_HOME_REQ_PAYMENT = 4\n",
    "    STATE_SAVE_TAX_ADV = 5\n",
    "    STATE_SAVE_TAXABLE = 6\n",
    "\n",
    "    MEG = 1.0e6\n",
    "\n",
    "    ACTION_ELEMENTS = 4\n",
    "    ACTION_HOME_LOAN = 0\n",
    "    ACTION_SAVE_TAX_ADV = 1\n",
    "    ACTION_SAVE_TAXABLE = 2\n",
    "    ACTION_LUXURY = 3\n",
    "\n",
    "    INFLATION = (0.015)/12.0\n",
    "    INTEREST = (0.05)/12.0\n",
    "    TAX_RATE = (.142)/12.0\n",
    "    EXPENSES = 0.6\n",
    "    INVEST_RETURN = 0.065/12.0\n",
    "    SALARY_LOW = 40000.0\n",
    "    SALARY_HIGH = 60000.0\n",
    "    START_AGE = 18\n",
    "    RETIRE_AGE = 80\n",
    "\n",
    "    def __init__(self, goal_velocity=0):\n",
    "      self.verbose = False\n",
    "      self.viewer = None\n",
    "\n",
    "      self.action_space = spaces.Box(\n",
    "          low=0.0,\n",
    "          high=1.0,\n",
    "          shape=(SimpleGameOfLifeEnv.ACTION_ELEMENTS,),\n",
    "          dtype=np.float32\n",
    "      )\n",
    "      self.observation_space = spaces.Box(\n",
    "          low=0,\n",
    "          high=2,\n",
    "          shape=(SimpleGameOfLifeEnv.STATE_ELEMENTS,),\n",
    "          dtype=np.float32\n",
    "      )\n",
    "\n",
    "      self.seed()\n",
    "      self.reset()\n",
    "\n",
    "      self.state_log = []\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def _calc_net_worth(self):\n",
    "      home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "      principal = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n",
    "      worth = home_value - principal\n",
    "      worth += self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV]\n",
    "      worth += self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE]\n",
    "      return worth\n",
    "\n",
    "    def _eval_action(self, action, payment):\n",
    "      # Calculate actions\n",
    "      act_home_payment = action[SimpleGameOfLifeEnv.ACTION_HOME_LOAN]\n",
    "      act_tax_adv_pay = action[SimpleGameOfLifeEnv.ACTION_SAVE_TAX_ADV]\n",
    "      act_taxable = action[SimpleGameOfLifeEnv.ACTION_SAVE_TAXABLE]\n",
    "      act_luxury = action[SimpleGameOfLifeEnv.ACTION_LUXURY]\n",
    "      if payment <=0:\n",
    "        act_home_payment = 0\n",
    "      total_act = act_home_payment + act_tax_adv_pay + act_taxable + act_luxury + self.expenses\n",
    "\n",
    "      if total_act <1e-2:\n",
    "        pct_home_payment = 0\n",
    "        pct_tax_adv_pay = 0\n",
    "        pct_taxable = 0\n",
    "        pct_luxury = 0\n",
    "      else:\n",
    "        pct_home_payment = act_home_payment / total_act\n",
    "        pct_tax_adv_pay = act_tax_adv_pay / total_act\n",
    "        pct_taxable = act_taxable / total_act\n",
    "        pct_luxury = act_luxury / total_act\n",
    "\n",
    "      return pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury\n",
    "\n",
    "    def step(self, action):\n",
    "      self.last_action = action\n",
    "      age = self.state[SimpleGameOfLifeEnv.STATE_AGE]\n",
    "      salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]\n",
    "      home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "      principal = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n",
    "      payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n",
    "      net1 = self._calc_net_worth()\n",
    "      remaining_salary = salary\n",
    "\n",
    "      # Calculate actions\n",
    "      pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury = \\\n",
    "        self._eval_action(action,payment)\n",
    "\n",
    "      # Expenses\n",
    "      current_expenses = salary * self.expenses\n",
    "      remaining_salary -= current_expenses\n",
    "      if self.verbose:\n",
    "        print(f\"Expenses: {current_expenses}\")\n",
    "        print(f\"Remaining Salary: {remaining_salary}\")\n",
    "\n",
    "      # Tax advantaged deposit action\n",
    "      my_tax_adv_deposit = min(salary * pct_tax_adv_pay, remaining_salary)\n",
    "      my_tax_adv_deposit = min(my_tax_adv_deposit, \\\n",
    "        self.year_tax_adv_deposit_left) # Govt CAP\n",
    "      self.year_tax_adv_deposit_left -= my_tax_adv_deposit\n",
    "      remaining_salary -= my_tax_adv_deposit\n",
    "      tax_adv_deposit = my_tax_adv_deposit * 1.05 # Company match\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] += \\\n",
    "        int(tax_adv_deposit)\n",
    "\n",
    "      if self.verbose:\n",
    "        print(f\"IRA Deposit: {tax_adv_deposit}\")\n",
    "        print(f\"Remaining Salary: {remaining_salary}\")\n",
    "\n",
    "      # Tax\n",
    "      remaining_salary -= remaining_salary * SimpleGameOfLifeEnv.TAX_RATE\n",
    "      if self.verbose:\n",
    "        print(f\"Tax Salary: {remaining_salary}\")\n",
    "\n",
    "      # Home payment\n",
    "      actual_payment = min(salary * pct_home_payment, remaining_salary)\n",
    "\n",
    "      if principal>0:\n",
    "        ipart = principal * SimpleGameOfLifeEnv.INTEREST\n",
    "        ppart = actual_payment - ipart\n",
    "        principal = int(principal-ppart)\n",
    "        if principal<=0:\n",
    "          principal = 0\n",
    "          self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = 0\n",
    "        elif actual_payment < payment:\n",
    "          self.late_count += 1\n",
    "          if self.late_count>15:\n",
    "            sell = (home_value-principal)/2\n",
    "            sell -= 20000\n",
    "            sell = max(sell,0)\n",
    "            self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += sell\n",
    "            principal = 0\n",
    "            home_value = 0\n",
    "            self.expenses += .3\n",
    "            self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = 0\n",
    "            if self.verbose:\n",
    "              print(f\"Foreclosure!!\")\n",
    "          else:\n",
    "            late_fee = payment * 0.1\n",
    "            principal += late_fee\n",
    "            if self.verbose:\n",
    "              print(f\"Late Fee: {late_fee}\")\n",
    "\n",
    "\n",
    "        self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN] = principal\n",
    "        remaining_salary -= actual_payment\n",
    "\n",
    "      if self.verbose:\n",
    "        print(f\"Home Payment: {actual_payment}\")\n",
    "        print(f\"Remaining Salary: {remaining_salary}\")\n",
    "\n",
    "      # Taxable savings\n",
    "      actual_savings = remaining_salary * pct_taxable\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += actual_savings\n",
    "      remaining_salary -= actual_savings\n",
    "\n",
    "      if self.verbose:\n",
    "        print(f\"Tax Save: {actual_savings}\")\n",
    "        print(f\"Remaining Salary (goes to Luxury): {remaining_salary}\")\n",
    "\n",
    "      # Investment income\n",
    "      return_taxable = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] * \\\n",
    "          self.invest_return\n",
    "      return_tax_adv = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] * \\\n",
    "          self.invest_return\n",
    "\n",
    "      return_taxable *= 1-SimpleGameOfLifeEnv.TAX_RATE\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE] += return_taxable\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV] += return_tax_adv\n",
    "\n",
    "      # Yearly events\n",
    "      if age>0 and age % 12 == 0:\n",
    "        self.perform_yearly()\n",
    "\n",
    "      # Monthly events\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_AGE] += 1\n",
    "      \n",
    "      # Time to retire (by age?)\n",
    "      done = self.state[SimpleGameOfLifeEnv.STATE_AGE] > \\\n",
    "        (SimpleGameOfLifeEnv.RETIRE_AGE*12)\n",
    "\n",
    "      # Calculate reward \n",
    "      net2 = self._calc_net_worth()\n",
    "      reward = net2 - net1\n",
    "\n",
    "      # Track progress\n",
    "      if self.verbose:\n",
    "        print(f\"Networth: {nw}\")\n",
    "        print(f\"*** End Step {self.step_num}: State={self.state}, \\\n",
    "          Reward={reward}\")\n",
    "      self.state_log.append(self.state + [current_expenses, actual_payment, \n",
    "      actual_savings, my_tax_adv_deposit, net2])\n",
    "      self.step_num += 1\n",
    "\n",
    "      # Normalize state and finish up\n",
    "      norm_state = [x/SimpleGameOfLifeEnv.MEG for x in self.state]\n",
    "      return norm_state, reward/SimpleGameOfLifeEnv.MEG, done, {}\n",
    "\n",
    "    def perform_yearly(self):\n",
    "      salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]\n",
    "      home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "      \n",
    "      self.inflation = SimpleGameOfLifeEnv.INTEREST + \\\n",
    "          self.np_random.normal(loc=0,scale=1e-2)\n",
    "      self.invest_return = SimpleGameOfLifeEnv.INVEST_RETURN + \\\n",
    "          self.np_random.normal(loc=0,scale=1e-2)\n",
    "\n",
    "      self.year_tax_adv_deposit_left = 19000\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_SALARY] = \\\n",
    "        int(salary * (1+self.inflation))\n",
    "\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE] \\\n",
    "        = int(home_value * (1+self.inflation))\n",
    "\n",
    "    def reset(self):\n",
    "      self.expenses = SimpleGameOfLifeEnv.EXPENSES\n",
    "      self.late_count = 0\n",
    "      self.step_num = 0\n",
    "      self.last_action = [0] * SimpleGameOfLifeEnv.ACTION_ELEMENTS\n",
    "      self.state = [0] * SimpleGameOfLifeEnv.STATE_ELEMENTS\n",
    "      self.state_log = []\n",
    "      salary = float(self.np_random.randint(low=SimpleGameOfLifeEnv.SALARY_LOW,\n",
    "                               high=SimpleGameOfLifeEnv.SALARY_HIGH))\n",
    "      house_mult = self.np_random.uniform(low=1.5,high=4)\n",
    "      value = round(salary*house_mult)\n",
    "      p = (value*0.9)\n",
    "      i = SimpleGameOfLifeEnv.INTEREST\n",
    "      n = 30 * 12\n",
    "      m = float(int(p *  ( i * (1 + i)**n ) / ( (1 + i)**n - 1)))\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_AGE] = \\\n",
    "        SimpleGameOfLifeEnv.START_AGE * 12\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_SALARY] = salary / 12.0\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE] = value\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN] = p\n",
    "      self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT] = m\n",
    "      self.year_tax_adv_deposit_left = 19000\n",
    "      self.perform_yearly()\n",
    "      return np.array(self.state)\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        screen_width = 600\n",
    "        screen_height = 400\n",
    "\n",
    "        img = PIL.Image.new('RGB', (600, 400))\n",
    "        d = PIL.ImageDraw.Draw(img)\n",
    "        font = ImageFont.load_default()\n",
    "        y = 0\n",
    "        _, height = d.textsize(\"W\", font)\n",
    "  \n",
    "        age = self.state[SimpleGameOfLifeEnv.STATE_AGE]\n",
    "        salary = self.state[SimpleGameOfLifeEnv.STATE_SALARY]*12\n",
    "        home_value = self.state[SimpleGameOfLifeEnv.STATE_HOME_VALUE]\n",
    "        home_loan = self.state[SimpleGameOfLifeEnv.STATE_HOME_LOAN]\n",
    "        home_payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n",
    "        balance_tax_adv = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAX_ADV]\n",
    "        balance_taxable = self.state[SimpleGameOfLifeEnv.STATE_SAVE_TAXABLE]\n",
    "        net_worth = self._calc_net_worth()\n",
    "\n",
    "        d.text((0, y), f\"Age: {age/12}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Salary: {salary:,}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Home Value: {home_value:,}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Home Loan: {home_loan:,}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Home Payment: {home_payment:,}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Balance Tax Adv: {balance_tax_adv:,}\", \\\n",
    "               fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Balance Taxable: {balance_taxable:,}\", \\\n",
    "               fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Net Worth: {net_worth:,}\", fill=(0, 255, 0))\n",
    "        y+=height*2\n",
    "\n",
    "        payment = self.state[SimpleGameOfLifeEnv.STATE_HOME_REQ_PAYMENT]\n",
    "        pct_home_payment, pct_tax_adv_pay, pct_taxable, pct_luxury = \\\n",
    "          self._eval_action(self.last_action,payment)\n",
    "        d.text((0, y), f\"Percent Home Payment: {pct_home_payment}\", \\\n",
    "               fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Percent Tax Adv: {pct_tax_adv_pay}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Percent Taxable: {pct_taxable}\", fill=(0, 255, 0))\n",
    "        y+=height\n",
    "        d.text((0, y), f\"Percent Luxury: {pct_luxury}\", fill=(0, 255, 0))\n",
    "\n",
    "        return np.array(img)\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='simple-game-of-life-v0',\n",
    "    entry_point=f'{__name__}:SimpleGameOfLifeEnv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2686643.752598176\n"
     ]
    }
   ],
   "source": [
    "env_name = 'simple-game-of-life-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "i = 0\n",
    "env.verbose = False\n",
    "while not done:\n",
    "    i += 1\n",
    "    #if i>36: break\n",
    "    # ACTION_HOME_LOAN = 0, ACTION_SAVE_TAX_ADV = 1, ACTION_SAVE_TAXABLE = 2\n",
    "    # ACTION_LUXURY = 3\n",
    "    state, reward, done, _ = env.step([1,1,0,0])\n",
    "    env.render()\n",
    "    \n",
    "env.close()\n",
    "print(env._calc_net_worth())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>salary</th>\n",
       "      <th>home_value</th>\n",
       "      <th>...</th>\n",
       "      <th>tax_deposit</th>\n",
       "      <th>tax_adv_deposit</th>\n",
       "      <th>net_worth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.08</td>\n",
       "      <td>3,941</td>\n",
       "      <td>100,175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,503.0</td>\n",
       "      <td>11,847.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.17</td>\n",
       "      <td>3,941</td>\n",
       "      <td>100,175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,516.0</td>\n",
       "      <td>13,084.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.25</td>\n",
       "      <td>3,941</td>\n",
       "      <td>100,175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,516.0</td>\n",
       "      <td>14,323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.33</td>\n",
       "      <td>3,941</td>\n",
       "      <td>100,175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,516.0</td>\n",
       "      <td>15,565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.42</td>\n",
       "      <td>3,941</td>\n",
       "      <td>100,175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1,516.0</td>\n",
       "      <td>16,809.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>79.75</td>\n",
       "      <td>5,676</td>\n",
       "      <td>145,283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>2,785,885.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>79.83</td>\n",
       "      <td>5,676</td>\n",
       "      <td>145,283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>2,760,799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>79.92</td>\n",
       "      <td>5,676</td>\n",
       "      <td>145,283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>2,735,957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>80.0</td>\n",
       "      <td>5,676</td>\n",
       "      <td>145,283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>2,711,357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>80.08</td>\n",
       "      <td>5,662</td>\n",
       "      <td>144,931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>568.0</td>\n",
       "      <td>2,686,644.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>745 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age salary home_value  ... tax_deposit tax_adv_deposit    net_worth\n",
       "0    18.08  3,941    100,175  ...         0.0         1,503.0     11,847.0\n",
       "1    18.17  3,941    100,175  ...         0.0         1,516.0     13,084.0\n",
       "2    18.25  3,941    100,175  ...         0.0         1,516.0     14,323.0\n",
       "3    18.33  3,941    100,175  ...         0.0         1,516.0     15,565.0\n",
       "4    18.42  3,941    100,175  ...         0.0         1,516.0     16,809.0\n",
       "..     ...    ...        ...  ...         ...             ...          ...\n",
       "740  79.75  5,676    145,283  ...         0.0           568.0  2,785,885.0\n",
       "741  79.83  5,676    145,283  ...         0.0           568.0  2,760,799.0\n",
       "742  79.92  5,676    145,283  ...         0.0           568.0  2,735,957.0\n",
       "743   80.0  5,676    145,283  ...         0.0           568.0  2,711,357.0\n",
       "744  80.08  5,662    144,931  ...         0.0           568.0  2,686,644.0\n",
       "\n",
       "[745 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(env.state_log, columns=SimpleGameOfLifeEnv.STATES)\n",
    "df = df.round(0)\n",
    "df['age'] = df['age']/12\n",
    "df['age'] = df['age'].round(2)\n",
    "for col in df.columns:\n",
    "  df[col] = df[col].apply(lambda x : \"{:,}\".format(x))\n",
    "\n",
    "pd.set_option('display.max_columns', 7)\n",
    "pd.set_option('display.max_rows', 12)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How long should training run?\n",
    "num_iterations = 50000 \n",
    "# How many initial random steps, before training start, to\n",
    "# collect initial data.\n",
    "initial_collect_steps = 1000   \n",
    "# How many steps should we run each iteration to collect \n",
    "# data from.\n",
    "collect_steps_per_iteration = 50\n",
    "# How much data should we store for training examples.\n",
    "replay_buffer_max_length = 100000\n",
    "\n",
    "batch_size = 64  \n",
    "#learning_rate = 1e-4 \n",
    "# How often should the program provide an update.\n",
    "log_interval = 2500  \n",
    "\n",
    "# How many episodes should the program use for each evaluation.\n",
    "num_eval_episodes = 100\n",
    "# How often should an evaluation occur.\n",
    "eval_interval = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciate the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'simple-game-of-life-v0'\n",
    "#env_name = 'MountainCarContinuous-v0'\n",
    "env = suite_gym.load(env_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=600x400 at 0x23B2AC9CF88>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "PIL.Image.fromarray(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_fc_layers=(400, 300)\n",
    "critic_obs_fc_layers=(400,)\n",
    "critic_action_fc_layers=None\n",
    "critic_joint_fc_layers=(300,)\n",
    "ou_stddev=0.2\n",
    "ou_damping=0.15\n",
    "target_update_tau=0.05\n",
    "target_update_period=5\n",
    "dqda_clipping=None\n",
    "td_errors_loss_fn=tf.compat.v1.losses.huber_loss\n",
    "gamma=0.995\n",
    "reward_scale_factor=1.0\n",
    "gradient_clipping=None\n",
    "\n",
    "actor_learning_rate=1e-4\n",
    "critic_learning_rate=1e-3\n",
    "debug_summaries=False\n",
    "summarize_grads_and_vars=False\n",
    "\n",
    "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
    "\n",
    "actor_net = actor_network.ActorNetwork(\n",
    "        train_env.time_step_spec().observation,\n",
    "        train_env.action_spec(),\n",
    "        fc_layer_params=actor_fc_layers,\n",
    "    )\n",
    "\n",
    "critic_net_input_specs = (train_env.time_step_spec().observation,\n",
    "                          train_env.action_spec())\n",
    "\n",
    "critic_net = critic_network.CriticNetwork(\n",
    "    critic_net_input_specs,\n",
    "    observation_fc_layer_params=critic_obs_fc_layers,\n",
    "    action_fc_layer_params=critic_action_fc_layers,\n",
    "    joint_fc_layer_params=critic_joint_fc_layers,\n",
    ")\n",
    "\n",
    "tf_agent = ddpg_agent.DdpgAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    critic_network=critic_net,\n",
    "    actor_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=actor_learning_rate),\n",
    "    critic_optimizer=tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=critic_learning_rate),\n",
    "    ou_stddev=ou_stddev,\n",
    "    ou_damping=ou_damping,\n",
    "    target_update_tau=target_update_tau,\n",
    "    target_update_period=target_update_period,\n",
    "    dqda_clipping=dqda_clipping,\n",
    "    td_errors_loss_fn=td_errors_loss_fn,\n",
    "    gamma=gamma,\n",
    "    reward_scale_factor=reward_scale_factor,\n",
    "    gradient_clipping=gradient_clipping,\n",
    "    debug_summaries=debug_summaries,\n",
    "    summarize_grads_and_vars=summarize_grads_and_vars,\n",
    "    train_step_counter=global_step)\n",
    "tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_episodes\n",
    "  return avg_return.numpy()[0]\n",
    "\n",
    "\n",
    "# See also the metrics module for standard implementations of different metrics.\n",
    "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_step(environment, policy, buffer):\n",
    "  time_step = environment.current_time_step()\n",
    "  action_step = policy.action(time_step)\n",
    "  next_time_step = environment.step(action_step.action)\n",
    "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "  # Add trajectory to the replay buffer\n",
    "  buffer.add_batch(traj)\n",
    "\n",
    "def collect_data(env, policy, buffer, steps):\n",
    "  for _ in range(steps):\n",
    "    collect_step(env, policy, buffer)\n",
    "\n",
    "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
    "                                                train_env.action_spec())\n",
    "\n",
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=tf_agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_max_length)\n",
    "\n",
    "collect_data(train_env, random_policy, replay_buffer, steps=100)\n",
    "\n",
    "# Dataset generates trajectories with shape [Bx2x...]\n",
    "dataset = replay_buffer.as_dataset(\n",
    "    num_parallel_calls=3, \n",
    "    sample_batch_size=batch_size, \n",
    "    num_steps=2).prefetch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 2500: loss = 0.00028442294569686055\n",
      "step = 5000: loss = 0.00033102420275099576\n",
      "step = 5000: Average Return = 8.053872108459473\n",
      "step = 7500: loss = 0.000518015876878053\n",
      "step = 10000: loss = 0.0016493176808580756\n",
      "step = 10000: Average Return = 7.547452926635742\n",
      "step = 12500: loss = 0.0006609844858758152\n",
      "step = 15000: loss = 0.0012456909753382206\n",
      "step = 15000: Average Return = 12.500370979309082\n",
      "step = 17500: loss = 0.027246102690696716\n",
      "step = 20000: loss = 0.05700862035155296\n",
      "step = 20000: Average Return = 13.190203666687012\n",
      "step = 22500: loss = 0.002985156374052167\n",
      "step = 25000: loss = 0.0011580710997805\n",
      "step = 25000: Average Return = 9.113201141357422\n",
      "step = 27500: loss = 0.042705439031124115\n",
      "step = 30000: loss = 0.0018809111788868904\n",
      "step = 30000: Average Return = 9.407532691955566\n",
      "step = 32500: loss = 0.0014804210513830185\n",
      "step = 35000: loss = 0.0015112801920622587\n",
      "step = 35000: Average Return = 7.586811065673828\n",
      "step = 37500: loss = 0.0009773785714060068\n",
      "step = 40000: loss = 0.012935971841216087\n",
      "step = 40000: Average Return = 8.134712219238281\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(dataset)\n",
    "\n",
    "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "# Reset the train step\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
    "  for _ in range(collect_steps_per_iteration):\n",
    "    collect_step(train_env, tf_agent.collect_policy, replay_buffer)\n",
    "\n",
    "  # Sample a batch of data from the buffer and update the agent's network.\n",
    "  experience, unused_info = next(iterator)\n",
    "  train_loss = tf_agent.train(experience).loss\n",
    "r\n",
    "  step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_iterations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-fa9c769d26ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_interval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Average Return'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Iterations'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_iterations' is not defined"
     ]
    }
   ],
   "source": [
    "iterations = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(iterations, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylim(top=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c06925170b90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0membed_mp4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mcreate_policy_eval_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"trained-agent\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf_agent' is not defined"
     ]
    }
   ],
   "source": [
    "def embed_mp4(filename):\n",
    "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "  video = open(filename,'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag = '''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)\n",
    "\n",
    "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
    "  filename = filename + \".mp4\"\n",
    "  with imageio.get_writer(filename, fps=fps) as video:\n",
    "    for _ in range(num_episodes):\n",
    "      time_step = eval_env.reset()\n",
    "      video.append_data(eval_py_env.render())\n",
    "      while not time_step.is_last():\n",
    "        action_step = policy.action(time_step)\n",
    "        time_step = eval_env.step(action_step.action)\n",
    "        video.append_data(eval_py_env.render())\n",
    "  return embed_mp4(filename)\n",
    "\n",
    "create_policy_eval_video(tf_agent.policy, \"trained-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
